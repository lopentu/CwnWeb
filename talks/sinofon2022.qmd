---
title: "Chinese Wordnet 2.0" 
subtitle: "Toward a dynamic interface of lexical synchrony and diachrony"
title-slide-attributes:
    data-background-image: ./figures/gil.jpg
    data-background-size: contain
    data-background-opacity: "0.3"
author: "Shu-Kai Hsieh"
institute: "National Taiwan University"
logo: lope.png
date: 'Sinofon@Olomouc, Nov 2, 2022'
format: 
  revealjs:
    theme: simple
execute: 
  enable: false
  cache: true

number-sections: false
bibliography: "/Users/shukai/Dropbox/BIB/cwn20.bib"
engine: knitr
page-layout: full
---

## Outline

-   Background
-   Chinese Wordnet 2.0: Concepts and Implmentation
-   Challenges and Current Works

::: notes
奇怪
:::

# History

`Sinica BOW` (@huang2004sinica, 2000-2004)

`Chinese Wordnet at Academia Sinica` (2005-2010)

`Chinese Wordnet at NTU Taiwan` (2010-)

::: callout-note
Note that there are more than one Chinese Wordnet.
:::

## WordNet architecture

Two core components:

-   Synset (synonymous set)
-   Paradigmatic lexical (semantic) relations: hyponymy/hypernymy; meronymy/holonymy, etc

![](./figures/wn.graph.png){fig-align="right"}

# Chinese Wordnet

-   Follow PWN (in comparison with Sinica BOW)

-   Word segmentation principle [@chu2017mandarin]

-   Corpus-based decision

-   Manually created (sense distinction, gloss with controlled vocabulary, etc)

## The status quo

-   latest release 2022
-   [website online](https://lopentu.github.io/CwnWeb/)

![](./figures/cwn.png){fig-align="right"}

## CWN 2.0 Programmable Search

-   The most comprehensive and fine-grained sense repository and network in Chinese
-   [API and doc](https://cwngraph.readthedocs.io/en/latest/) freely available

![](./figures/eat.png){fig-align="left"}

# Theories

::: callout-tip
## Some new perspectives in CWN

sense granularity, relation discovery, and gloss with annotation
:::

## Meaning facets vs senses

::: columns
::: {.column width="50%"}
![](./figures/co-predication.png)
:::

::: {.column width="50%"}
> 埔里*種*的【茶】很*好喝*
:::
:::

::: callout-tip
## Co-predicative Nouns

a phenomenon where two or more predicates seem to require that their argument denotes different things.
:::

## Leveraging morpho-semantic relations

::: {#fig-morsem layout-ncol="2"}
![@hsieh2014leveraging](./figures/morSem1.png){#fig-surus}

![@tseng2019augmenting](./figures/morSem2.png){#fig-hanno}

Different leveraging methods
:::

## Gloss as lexicographic resources with add-ons annotations

-   Gloss (\`lexicographic definition') is carefully controlled with limited vocabulary and **patterns**, e.g.,

    -   Verbs with `VH` tag (i.e., stative intransitive verbs) are glossed with "形容 or 比喻形容 ...".
    -   Adverbs are glossed with "表..."

-   collocational information, pragmatic information ('tone', etc) are recorded as additional annotation.

# Data Statistics

## Zipf's law (no surprise)

-   Most words have small number of senses (Zipf's law)

![](figures/comp.jpg)

## Comparison with others

-   CWN is the best candidate

<p align="center">

<img src="./figures/eHowNet.png" alt="drawing" style="width:300px;"/> <img src="./figures/moe.png" alt="drawing" style="width:300px;"/> <img src="./figures/cwnSense.png" alt="drawing" style="width:500px;"/>

</p>

## Data summary 1/1

@fig-cwn1 shows the lemma and sense data distribution

```{r}
#| label: fig-cwn1
#| fig-cap: cwn sense data summary
#| warning: false
df <- tribble(
  ~POS, ~count,
  "Adj", 2714,
  "Adv", 2057,
  "N", 12519,
  "V", 13511,
)

ggplot(df) +
  geom_col(aes(x=reorder(POS, -count), y=count, fill=POS)) + 
  labs(x="POS", y="count") + 
  guides(fill="none") +
  geom_text(aes(x=reorder(POS, -count), y=count+400, label=count)) +
  labs(title = str_c("Total Sense Count = ", sum(df$count)))
```

## Data summary 2/2

@fig-cwn2 further demonstrates the distribution of different types of relations

```{r}
#| label: fig-cwn2
#| fig-cap: cwn relation data summary
#| warning: false

library(tidyverse)
library(ggplot2)

df <- read_csv("./data/relations.csv") %>% rename(relation_type = sense_type)
df %>% count(relation_type) %>% ggplot() + geom_col(aes(x=reorder(relation_type, n), y=n, fill=relation_type)) + coord_flip() + labs(y="count", x="relation") + guides(fill="none") + theme(axis.title = element_text(size = 16), axis.text = element_text(size = 14)) 
```

## Data summary 3/3

Gloss statistics

![](./figures/glossStat.png)

# GraphAPI and Visualization

![](./figures/cwnVis.png)

# Computational Semantic Representations

-   human curated and machine generated lexical semantic resources
-   open-sourced ([github](https://github.com/lopentu))

## `SemCor` manually sense-tagged corpus

![](figures/senseanno.png){fig-align="left"}

![](figures/semcor.png){fig-align="right"}

## Word Sense Tagger

WSD: The Problems

-   The task as currently defined does not allow for generalization over different words $\rightarrow$ learning is word-specific.

-   Need training data for every sense of every word, and no chance with unknown words. (unsupervised approaches perform consistently worse than supervised approaches)

-   Cannot capture the sense alternation regularities ![](./figures/nlpPipe.png){fig-align="right"}

## Distributed approach to model the 'Gradience'

-   *gradience* is found is many linguistic categories.

-   Regular polysemy detection: Using word vector [@di2013regular]or sense vector [@lopukhina2016regular] to detect sense alternations (such as `FOOD` or `ANIMAL`)

-   Recent **(contextualized) vector representation** could help us in locating where a word meaning is on the continuum (/in the multidimensional semantic space).

## WSD with Transformer (1)

-   Leveraging wordnet *glosses* using `GlossBert` [@huang2019glossbert]
    -   a BERT model for word sense disambiguation with gloss knowledge.
-   Our extended `GlossBert` model on CWN gloss+SemCor reports 82% accuracy.

::: notes
conducting *context-gloss* pairs, and fine-tune the pre-trained BERT model on SemCor3.0 training corpus, and achieves SOTA performance on several English all-words WSD tasks.
:::

![](figures/glossB.png)

## Word Sense Tagger

-   APIs (GlossBert version) released in 2021\
    <img src="./figures/tagger.png" alt="drawing" style="width:400px;"/>

```{python}
#| eval: false
#| echo: true
# pip install -U DistilTag SenseTagger
import DistilTag
import CwnSenseTagger
DistilTag.download()
CwnSenseTagger.download()

tagger = DistilTag()
tagged = tagger.tag("<raw text>")
sense_tagged = senseTag(tagged)
```

![](./figures/senseTag.png){fig-align="center"}

## Word Sense frequencies

-   Now we have chance to *empirically* explore the **dominancy** of word senses, which is essential for both lexical semantic and psycholinguistic studies.

    -   e.g., '開' (kai1,'open') has (surprisingly) more dominant *blossom* sense over others (based on randomly chosen 300 sentences in ASBC corpus)

![](./figures/senseFreq.png){fig-align="center"}

::: notes
從平衡語料庫中取出 300 句包含「吃」或「開」的句子（一句可能含多個目標詞），用CwnSenseTagger 判斷該詞在脈絡中的詞意，並計算其頻率。以下列出頻率最高的 5 個詞意。
:::

## Word Sense Embeddings

-   We use our tagger to automatically tag ca. 5 millions word tokens in Academia Sinica Balanced Corpus, and indexed the annotated sense.
    -   **word sense frequency data** are calculated out via the tags.
    -   tokenize the index and use **word2vec** to get the word sense embeddings.

::: notes
藉由詞意標記模型，我們對平衡語料庫中約500萬字的語料進行詞意自動標記。藉由這些標記，我們可計算出每個詞意在語料庫中的出現頻率。 標記完成之後，每個被標定詞意的詞，都會在該詞之後註明其詞意序號，例如： 「一切（Neqa）　公私（Na）　關係（Na）」 「一切-03049601　公私　關係-05186502」 把每個包含詞意序號的詞當成token，我們就可藉由word2vec計算其word (sense) embeddings
:::

## Other related works

-   Resolving Regular Polysemy in Named Entities (Hsieh et al. submitted)

![](./figures/ner.wsd.png)

---

-   `Character Jacobian`: Chinese character (root morpheme) lies in the meaning core [@tseng2022character]

-   `gloss2vec` (Hsieh et al. 2022. submitted)



# Chinese(s) in Synchrony and Diachrony

> *Gradualness* change and *continual* variations

## Contemporary Mandarin Varieties

-   Fusion of Archaic and Modern senses

    -   resulting in (*expressive vs receptive* word senses). E.g. 【打】水 (`to pump our water out of a well'.)

::: notes
languages strive for diversity XD 懂得與使用, not written vs oral distinction Expressive vocabulary refers to the words that we use to express our thoughts and ideas. That is all the words that we use for "speaking" and "writing" fall under the expressive category. Receptive vocabulary, on the other hand, refers to all the words that you understand while "reading" books or "listening" to someone speak.
:::

## Contemporary Mandarin Varieties

The puzzle of `affixoid`

> The morphological status of affixes in Chinese has long been a matter of debate. How one might apply the conventional criteria of free/bound and content/function features to distinguish word-forming affixes from bound roots in Chinese is still far from clear. Issues involving polysemy and diachronic dynamics further blur the boundaries. [@tseng2020computational]

-   E.g. 【化】(huà, '-ize')

## Change of affixiod status in diachrony

-   The indeterminate nature of Chinese affixoids
-   Sense status of 家 jiā from the Tang dynasty to the 1980s

![](./figures/jia_en.png){fig-align="center"}

::: notes
用論文講久一點
:::

## Dynamics in Contemporary Mandarin Chinese(s)

[【真香】 ('zhēn xiāng', soappetizing)](https://baike.baidu.hk/item/%E7%9C%9F%E9%A6%99/22700736)

![](./figures/zhenXiang.png)

## Dynamics in Contemporary Mandarin Chinese(s)

word, construction, word senses

-   originally appeared as a fixed phrase in MC (cannot be replaced with other synonymous phrases like 好香)
-   gradually spread into TM, but diversified itself into new construction senses, as well as word sense.

## World Chinese(s) and Construction Grammar (CxG)

-   We've build a **parallel corpus** of Mandarin in Mainland China and Taiwan, and

-   Corpus data collected from movie titles and TED talks.

-   A *intralingual* Machine Translation system has been developed and Sense Mapping/Inducing system is in process.

------------------------------------------------------------------------

![](./figures/chivar.png)

# Challenges and On-going Works

> The haunting issues of `wordhood` (and the beautiful scene it has brought us into)

## Re-theorizing

`Chinese Wordnet beyond word`

-   Form-meaning pairs

-   Construction has its own sense

    -   ( '還在那邊')

-   Need to broaden the concept of word

-   Construction Sense Disambiguation

::: notes
晴方
:::

## Re-structuring Ontologies

-   synset-structured (lexicalized) ontology doesn't (seem) work well

-   unlabeled root vs embodied body

::: {layout-ncol="3"}
![sumo](./figures/sumo.png)

![dolce](./figures/dolce.png)

![quantum](./figures/quantumTensor.png)
:::

# Conclusions

-   Chinese(s) are neighbors themselves.

-   Wordnet framework serves as a mirror for Chinese synchronic and diachronic varieties.

# Reference
