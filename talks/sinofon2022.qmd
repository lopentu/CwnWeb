---
title: "Chinese Wordnet 2.0" 
subtitle: "Toward a dynamic interface of lexical synchrony and diachrony"
author: "Shu-Kai Hsieh"
institute: "National Taiwan University"
logo: lope.png
date: 'Sinofon@Olomouch, Nov 2, 2022'
format: 
  revealjs:
    theme: simple
execute: 
  enable: false
  cache: true

number-sections: false
bibliography: "/Users/shukai/Dropbox/BIB/cwn20.bib"
engine: knitr
page-layout: full
---

<!-- # Abstract -->

<!-- In this talk, I'll first present the current status of Chinese Wordnet (CWN 2.0), including the manually created sense-related resources and their computational representations (sense embeddings, gloss vectors, sense-tagged corpus) and applications (WSD, etc.). Then I'll discuss the challenges of developing wordnet-like resources in the Chinese context from diachronic and synchronic perspectives. -->

# TOC

-   Background
-   Chinese Wordnet 2.0: Concepts and Implmentation
-   Challenges and Current Works

::: notes
奇怪
:::

# History

`Sinica BOW` (@huang2004sinica, 2000-2004)

`Chinese Wordnet at Academia Sinica` (2005-2010)

`Chinese Wordnet at NTU Taiwan` (2010-)

::: callout-note
Note that there are many Chinese Wordnet(s).
:::

## WordNet architecture

-   synset (synonymous set)
-   Lexical relations

![](./figures/wn.graph.png){fig-align="right"}

# Chinese Wordnet

-   Follow PWN (in comparison with Sinica BOW)

-   Word segmentation principle [@chu2017mandarin]

-   Corpus-based decision

-   Manually created (sense distinction, gloss with controlled vocabulary, etc)

## History and Status qua

-   latest release 2022

![](./figures/cwn.png)

## CWN 2.0

-   The most comprehensive and fine-grained sense repository and network in Chinese

![](./figures/eat.png)

# Theories

## Meaning facets vs senses

(co-predication)

## Leveraging Morpho-semantic relations

::: notes
之前paper？
:::

## Gloss as lexicographic resources with add-ons annotations

::: notes
gloss2vec
:::

# Data Statistics

## Zipf's law (no surprise)

-   Most words have small number of senses (Zipf's law)

![](figures/comp.jpg)

## Comparison with others

-   CWN is the best candidate

<p align="center">

<img src="./figures/eHowNet.png" alt="drawing" style="width:300px;"/> <img src="./figures/moe.png" alt="drawing" style="width:300px;"/> <img src="./figures/cwnSense.png" alt="drawing" style="width:500px;"/>

</p>

## test

```{ojs}
//| panel: input
viewof bill_length_min = Inputs.range(
  [32, 50], 
  {value: 35, step: 1, label: "Bill length (min):"}
)
viewof islands = Inputs.checkbox(
  ["Torgersen", "Biscoe", "Dream"], 
  { value: ["Torgersen", "Biscoe"], 
    label: "Islands:"
  }
)
```

::: panel-tabset
## Plot

```{ojs}
Plot.rectY(filtered, 
  Plot.binX(
    {y: "count"}, 
    {x: "body_mass_g", fill: "species", thresholds: 20}
  ))
  .plot({
    facet: {
      data: filtered,
      x: "sex",
      y: "species",
      marginRight: 80
    },
    marks: [
      Plot.frame(),
    ]
  }
)
```

## Data

```{ojs}
Inputs.table(filtered)
```
:::

```{ojs}
data = FileAttachment("penguins.csv").csv({ typed: true })
```

```{ojs}
filtered = data.filter(function(penguin) {
  return bill_length_min < penguin.bill_length_mm &&
         islands.includes(penguin.island);
})
```

## Gloss statistics

![](./figures/glossStat.png)

<!-- @fig-airquality further explores the impact of temperature on ozone level. -->

<!-- ```{r} -->

<!-- #| label: fig-airquality -->

<!-- #| fig-cap: Temperature and ozone level. -->

<!-- #| warning: false -->

<!-- library(ggplot2) -->

<!-- ggplot(airquality, aes(Temp, Ozone)) +  -->

<!--   geom_point() +  -->

<!--   geom_smooth(method = "loess") -->

<!-- ``` -->

# GraphAPI and Visualization

![](./figures/cwnvis.png)

## Network Visualization

```{r}
#library(visNetwork)
#visNetwork(nodes, links, width="100%", height="400px", background="#eeefff",
#           main="Network", submain="And what a great network it is!",
#           footer= "Hyperlinks and mentions among media sources")


```

# Computational Semantic Representations

-   human curated and machine generated lexical semantic resources
-   open-sourced ([github](https://github.com/lopentu))

## `SemCor` manually sense-tagged corpus

![](figures/senseanno.png){fig-align="left"}

![](figures/semcor.png){fig-align="right"}

## Word Sense Tagger

WSD: The Problems

-   The task as currently defined does not allow for generalization over different words $\rightarrow$ learning is word-specific.

-   Need training data for every sense of every word, and no chance with unknown words. (unsupervised approaches perform consistently worse than supervised approaches)

-   Cannot capture the sense alternation regularities ![](./figures/nlpPipe.png)

## Distributed approach to model the 'Gradience'

-   *gradience* is found is many linguistic categories.

-   Regular polysemy detection: Using word vector [@di2013regular]or sense vector [@lopukhina2016regular] to detect sense alternations (such as `FOOD` or `ANIMAL`)

-   Recent **(contextualized) vector representation** could help us in locating where a word meaning is on the continuum (/in the multidimensional semantic space).

## WSD with Transformer (1)

-   Leveraging wordnet *glosses*. using `GlossBert` [@huang2019glossbert]
    -   a BERT model for word sense disambiguation with gloss knowledge.
-   Our extended `GlossBert` model on CWN gloss+SemCor reports 82% accuracy.

::: notes
conducting *context-gloss* pairs, and fine-tune the pre-trained BERT model on SemCor3.0 training corpus, and achieves SOTA performance on several English all-words WSD tasks.
:::

![](figures/glossB.png)

## Word Sense Tagger

-   APIs (GlossBert version) released in 2021\
    <img src="./figures/tagger.png" alt="drawing" style="width:100px;"/>

```{python}
#| eval: false
#| echo: true
# pip install -U DistilTag SenseTagger
import DistilTag
import CwnSenseTagger
DistilTag.download()
CwnSenseTagger.download()

tagger = DistilTag()
tagged = tagger.tag("<raw text>")
sense_tagged = senseTag(tagged)
```

![](./figures/senseTag.png)

## Word Sense frequencies

-   Now we have chance to *empirically* explore the **dominancy** of word senses. For both lexical semantics and psycholinguistics

    -   e.g., '開' (kai1,'open') has more dominant *blossom* sense over others (based on randomly chosen 300 sentences in ASBC corpus)

![](./figures/senseFreq.png)

::: notes
從平衡語料庫中取出 300 句包含「吃」或「開」的句子（一句可能含多個目標詞），用CwnSenseTagger 判斷該詞在脈絡中的詞意，並計算其頻率。以下列出頻率最高的 5 個詞意。
:::

## Word Sense Embeddings

-   we use our tagger to automatically tag ca. 5 millions word tokens in ASBC, indexed the annotated sense.
    -   **word sense frequency data** are calculated out via the tags.
    -   tokenize the index and use **word2vec** to get the word sense embeddings.

::: notes
藉由詞意標記模型，我們對平衡語料庫中約500萬字的語料進行詞意自動標記。藉由這些標記，我們可計算出每個詞意在語料庫中的出現頻率。 標記完成之後，每個被標定詞意的詞，都會在該詞之後註明其詞意序號，例如： 「一切（Neqa）　公私（Na）　關係（Na）」 「一切-03049601　公私　關係-05186502」 把每個包含詞意序號的詞當成token，我們就可藉由word2vec計算其word (sense) embeddings
:::

## Other related works

-   Resolving Regular Polysemy in Named Entities (Hsieh et al. submitted)
-   `gloss2vec`
-   Jacob character: -Chinese character (root morpheme) lies in the meaning core

## Regular Polysemy

![](./figures/ner.wsd.png)

# Chinese(s) in Synchrony and Diachrony

> *Gradualness* change and *continual* variations

## Contemporary Mandarin Varieties

-   Fusion of Archaic and Modern senses

    -   resulting in (*expressive vs receptive* word senses)
    -   例子

::: notes
languages strive for diversity XD 懂得與使用, not written vs oral distinction Expressive vocabulary refers to the words that we use to express our thoughts and ideas. That is all the words that we use for "speaking" and "writing" fall under the expressive category. Receptive vocabulary, on the other hand, refers to all the words that you understand while "reading" books or "listening" to someone speak.
:::

## Contemporary Mandarin Varieties

The puzzle of `affixoid`

> The morphological status of affixes in Chinese has long been a matter of debate. How one might apply the conventional criteria of free/bound and content/function features to distinguish word-forming affixes from bound roots in Chinese is still far from clear. Issues involving polysemy and diachronic dynamics further blur the boundaries. [@tseng2020computational]

-   例子

## Change of affixiod status in diachrony

-   The indeterminate nature of Chinese affixoids
-   Sense status of 家 jiā from the Tang dynasty to the 1980s

![](./figures/jia_en.png){fig-align="center"}

::: notes
用論文講久一點
:::

## Contemporary Mandarin Chinese Dynamics

[【真香】 ('zhēn xiāng', soappetizing)](https://baike.baidu.hk/item/%E7%9C%9F%E9%A6%99/22700736)

![](./figures/zhenXiang.png)

## Contemporary Mandarin Chinese Dynamics

word, construction, word senses

-   originally appeared as a fixed phrase in MC (cannot be replaced with other synonymous phrases like 好香)
-   gradually spread into TM, but diversified itself into new construction senses, as well as word sense.

## World Chinese(s) and Construction Grammar (CxG)

-   We've build a **parallel corpus** of Mandarin in Mainland China and Taiwan, and

-   Corpus data collected from movie titles and TED talks.

-   A *intralingual* Machine Translation system has been developed and Sense Mapping/Inducing system is in process.

------------------------------------------------------------------------

![](./figures/chivar.png)

# Challenges and On-going Works

> The haunting issues of `wordhood` (and the beautiful scene it has brought us into)

## Re-theorizing

`Chinese Wordnet beyond word`

-   Form-meaning pairs

-   Construction has its own sense

    -   ( '還在那邊')

-   Need to broaden the concept of word

-   Construction Sense Disambiguation

::: notes
晴方
:::

## Re-structuring Ontologies

-   synset-structured (lexicalized) ontology doesn't (seem) work well

-   unlabeled root vs embodied body 

::: {layout-ncol="3"}
![sumo](./figures/sumo.png)

![dolce](./figures/dolce.png)

![quantum](./figures/quantumTensor.png)
:::

# Conclusions

-   Chinese(s) are neighbors themselves.

-   Wordnet framework serves as a mirror for Chinese synchronic and diachronic varieties.

# Reference
